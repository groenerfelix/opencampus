---
title: "R Notebook"
output: html_notebook
---
To-Do:
- Pattis, Finns und weitere Daten einbinden.
- Problem lösen, wie die Modelle für die einzelnen Warengruppen erstellt werden können
- - Warengruppe als unabhängige Variable? (Vielleicht als WGxTemp + WGxWochentag + ...)
- - Oder für jede Warengruppe ein eigenes Modell? (Das würde ich vorziehen)
- Plots mit Konfidenzintervallen für zwei Variablen erstellen
- Mit verschiedenen Modellen herumerxperimentieren, welche den geringsten MAPE haben

Im ersten Block werden alle benötigten Libraries und Tabellen importiert.
```{r, message=FALSE}
library(readr)
library(lubridate)
library(ggplot2)
library(dplyr)
library(gtools)
library(timeDate)
library(chron)
library(e1071)
library(StatMeasures)

umsatzdaten <- read_csv("umsatzdaten_gekuerzt.csv")
kiwo <- read_csv("kiwo.csv")
wetter <- read_csv("wetter.csv")
#flohmarkt <- read_csv("flohmarkt.csv")
#gefuehlteTemp <- read_csv("gefuehlte_Temperatur.csv")
#kielmachtauf <- read_csv("kielmachtauf.csv")
```

Im zweiten Block werden die Tabellen gejoint und die Spalten angepasst.
```{r, message=FALSE}
#FEIERTAGE
#scheint noch nicht ganz perfekt zu sein, weil u.a. Karsamstag inkludiert ist
#hlist <- c("Easter","DEAscension","DEGermanUnity","DEChristmasEve","DENewYearsEve")
hlist <- c("EasterSunday","EasterMonday","Ascension", "PentecostMonday","DEGermanUnity","ChristmasDay", "NewYearsDay")
#TODO: weitere Feiertage raussuchen https://zufish.schleswig-holstein.de/detail?areaId=&pstId=8967760&ouId=&infotype=0
feiertage <- data.frame(Datum = as.Date(dates(as.character(holiday(2012:2019,hlist)), format="Y-M-D")))
feiertage$Feiertag <- 1
head(feiertage)

#JOIN EVERYTHING
umsatzdaten <- left_join(umsatzdaten, wetter)
umsatzdaten <- left_join(umsatzdaten, kiwo)
umsatzdaten$KielerWoche <- na.replace(umsatzdaten$KielerWoche, 0) #damit 0 und nicht "na" steht, wenn keine KiWo ist
umsatzdaten <- left_join(umsatzdaten, feiertage)
umsatzdaten$Feiertag <- na.replace(umsatzdaten$Feiertag, 0) #dasselbe bei Feiertagen
#umsatzdaten <- left_join(umsatzdaten, kielmachtauf)
#umsatzdaten <- left_join(umsatzdaten, flohmarkt)
#umsatzdaten <- left_join(umsatzdaten, gefuehlteTemp, by="Datum")
head(umsatzdaten)
#WOCHENTAGE, MONATE UND AS FACTOR
umsatzdaten <- mutate(umsatzdaten, Wochentag = as.factor(weekdays(Datum)), Monat = as.factor(month(Datum)), Feiertag = as.factor(Feiertag), KielerWoche = as.factor(KielerWoche))#, Flohmarkt = as.factor(flohmarkt), Kielmachtauf = as.factor(Kielmachtauf))

#Export der finalen Umsatzdaten als CVS für NN in repo
write.csv(umsatzdaten, "umsatzdaten_final" , row.names=FALSE)

```

Hier erstelle ich jetzt verschiedene Datasets - Felix
```{r, message=FALSE}
#zu Testzwecken haben ich erstmal nur die Warengruppe 1 gefiltert, weil ich nicht weiß, wie das sonst geht
reg_data <- filter(umsatzdaten, Warengruppe == 1) %>% select(Datum, Umsatz, Wochentag, KielerWoche, Feiertag, Bewoelkung, Temperatur, Windgeschwindigkeit)

#alle Zeilen herausfilter, die irgendwo ein NA haben
reg_data <- reg_data[complete.cases(reg_data),]
stopifnot(sum(is.na(reg_data)) == 0)

#SPLIT TRAINING AND TESTING SETS
set.seed(1665)
sample_size <- floor(0.70 * nrow(reg_data)) # 70% - 30%
sample_ids <- sample(seq_len(nrow(reg_data)), size = sample_size)

training_data <- reg_data[sample_ids, ]
testing_data <- reg_data[-sample_ids, ]

```

Hier wird ein SVM-Modell getuned. Dann werden die MAPEs der Vorhersage für den Trainings- und Testdatensatz berechnet. - Felix
```{r, message=FALSE}
#CREATING THE SVM MODEL
#svm_model <- svm(training_data$Umsatz ~ ., data=training_data)
#summary(svm_model)
#sum(umsatzdaten$KielerWoche == 1)
tune_data <- tune(svm, Umsatz ~ Wochentag + KielerWoche + Feiertag +  Bewoelkung + Temperatur + Windgeschwindigkeit, data=training_data, ranges = list(epsilon = seq(0.2, 1, 0.1), cost = 2^(2:3))) 


#ERGEBNISSE
#print(tune_data)
best_model <- tune_data[["best.model"]]
summary(best_model) #epsilon: 0.4, cost: 4

#PREDICTIONS
prediction_training <- predict(best_model)
prediction_test <- predict(best_model, newdata=testing_data)
rbind(MAPE = c(Training = mape(prediction_training, training_data$Umsatz), Test = mape(prediction_test, testing_data$Umsatz)))

```

Hier sollte dann die Prognose für neue Daten kommen. - Felix
```{r, message=FALSE}
neues_datum <- data.frame(Datum = seq.Date(from = as.Date("2019-06-04"), to = as.Date("2019-08-01"), by = "day"))

#JOIN EVERYTHING
neues_datum <- left_join(neues_datum, wetter)
neues_datum <- left_join(neues_datum, kiwo)
neues_datum$KielerWoche <- na.replace(neues_datum$KielerWoche, 0) #damit 0 und nicht "na" steht, wenn keine KiWo ist
neues_datum <- left_join(neues_datum, feiertage)
neues_datum$Feiertag <- na.replace(neues_datum$Feiertag, 0) #dasselbe bei Feiertagen

#WOCHENTAGE, MONATE UND AS FACTOR
neues_datum <- mutate(neues_datum, Wochentag = as.factor(weekdays(Datum)), Monat = as.factor(month(Datum)), Feiertag = as.factor(Feiertag), KielerWoche = as.factor(KielerWoche))
#lapply(neues_datum, nlevels)
#alle Zeilen herausfilter, die irgendwo ein NA haben
neues_datum <- neues_datum[complete.cases(neues_datum),]

#die restlichen Umsätze für 2019 berechnen
neues_datum$Umsatz <- predict(best_model, newdata=neues_datum)

#Hier das zu berechnende Datum heraussuchen
filter(neues_datum, Datum == as.Date("2019-06-04"))

#ERKLÄRUNG: Wir müssen dem Umsatz für viel mehr als nur ein Datum prognostizieren, damit von allen Faktorvariablen auch mindestens zwei Ausprägungen vorhanden sind (also Kieler Woche und Feiertage müssen enthalten sein)

```
